{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71baa4a9",
   "metadata": {},
   "source": [
    "# Notebook to train the model\n",
    "This notebook train a UNET model based on training data in /data/raw/train_features/\n",
    "\n",
    "There are two parameters to set before starting the notebook.\n",
    "- the model name\n",
    "- the train test split\n",
    "\n",
    "My approach is based on the average of three similar UNET model trained on different data.  \n",
    "By choosing TRAIN_TEST_SPLIT = 1, 2 or three you train one of the three models.\n",
    "\n",
    "\n",
    "Also depending on your memory you might have to change the batch_size.  \n",
    "For me 8 seems to work most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ffa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"test_1.h5\"    #here you can choose the name of the h5 file where the model fill be saved\n",
    "TRAIN_TEST_SPLIT = 1        #here you can choose the train/test split. Possible choice: 1, 2 or 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41afac23",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f60dc26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed9d11c1",
    "outputId": "427e9a8c-8bda-4ff2-fbe6-3ca28e67723c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from pathlib import Path\n",
    "!pip install pandas_path\n",
    "from pandas_path import path\n",
    "\n",
    "!pip install rasterio\n",
    "import rasterio\n",
    "\n",
    "import albumentations\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bdef4",
   "metadata": {},
   "source": [
    "## Only for training on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9263c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VBjgAUsKifaW",
    "outputId": "ce46239f-6f0e-4089-f2ad-c03fa24cfe06"
   },
   "outputs": [],
   "source": [
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9700d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJBCecyV7goE",
    "outputId": "b5048e3f-cfbc-44d6-bbe8-dd7482bc18a9"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d783d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = Path.cwd().parent / \"content\" / \"drive\" / \"MyDrive\" / \"DATA SCIENCE\" / \"data google colab\" / \"floodwater\" / \"train_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6015657",
   "metadata": {
    "id": "6604c660"
   },
   "source": [
    "## Load the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d72f53",
   "metadata": {
    "id": "w3-kRONT6sM9"
   },
   "outputs": [],
   "source": [
    "img_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe579a8a",
   "metadata": {
    "id": "6a3bce35"
   },
   "outputs": [],
   "source": [
    "# This is where our downloaded images and metadata live locally\n",
    "DATA_PATH = Path.cwd().parent.parent / \"data\" / \"raw\" / \"train_features\"\n",
    "ADDITIONAL_DATA_PATH = Path.cwd().parent.parent / \"data\" / \"external\"\n",
    "train_metadata = pd.read_csv(\n",
    "    DATA_PATH / \"flood-training-metadata.csv\", parse_dates=[\"scene_start\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbe0b3",
   "metadata": {
    "id": "124f9f14"
   },
   "outputs": [],
   "source": [
    "#adding the path to the images and labels in the dataframe\n",
    "train_metadata[\"feature_path\"] = (str(DATA_PATH / \"train_features\")\n",
    "    / train_metadata.image_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"change\"] = (str(ADDITIONAL_DATA_PATH / \"jrc_change\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"extent\"] = (str(ADDITIONAL_DATA_PATH / \"jrc_extent\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"occurrence\"] = (str(ADDITIONAL_DATA_PATH / \"jrc_occurrence\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"recurrence\"] = (str(ADDITIONAL_DATA_PATH / \"jrc_recurrence\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"seasonality\"] = (str(ADDITIONAL_DATA_PATH / \"jrc_seasonality\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"transitions\"] = (str(ADDITIONAL_DATA_PATH / \"jrc_transitions\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"nasadem\"] = (str(ADDITIONAL_DATA_PATH / \"nasadem\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)\n",
    "\n",
    "train_metadata[\"label_path\"] = (str(DATA_PATH / \"train_labels\")\n",
    "    / train_metadata.chip_id.path.with_suffix(\".tif\").path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1799e",
   "metadata": {
    "id": "e6b2509d"
   },
   "source": [
    "## Split the training data into train and test\n",
    "We split the train test dataset in three different ways depending on the model we are building.\n",
    "At the end we average the prediction of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d573e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20b905d7",
    "outputId": "d8124fe0-4e89-4a36-ebd1-2abfd7cb11d3"
   },
   "outputs": [],
   "source": [
    "test_ids = [['kuo', 'wvy', 'awc'] , ['coz', 'qxb', 'ayt'] , ['hbe', 'jja']]\n",
    "val_flood_ids = test_ids[TRAIN_TEST_SPLIT-1]\n",
    "val_flood_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c8a16",
   "metadata": {
    "id": "c6a1fbc8"
   },
   "outputs": [],
   "source": [
    "test = train_metadata[train_metadata.flood_id.isin(val_flood_ids)]\n",
    "train = train_metadata[~train_metadata.flood_id.isin(val_flood_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1f229",
   "metadata": {
    "id": "c9bb058d"
   },
   "outputs": [],
   "source": [
    "def get_paths_by_chip(image_level_df):\n",
    "    \"\"\"\n",
    "    Function that take as input the meta_dataframe\n",
    "    and return a dataframe with the chip id and both path for vv and vh.\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = []\n",
    "    for chip, group in image_level_df.groupby(\"chip_id\"):\n",
    "        vv_path = group[group.polarization == \"vv\"][\"feature_path\"].values[0]\n",
    "        vh_path = group[group.polarization == \"vh\"][\"feature_path\"].values[0]\n",
    "        nasadem_path = group[\"nasadem\"].values[0]\n",
    "        change_path = group[\"change\"].values[0]\n",
    "        extent_path = group[\"extent\"].values[0]\n",
    "        occurrence_path = group[\"occurrence\"].values[0]\n",
    "        recurrence_path = group[\"recurrence\"].values[0]\n",
    "        seasonality_path = group[\"seasonality\"].values[0]\n",
    "        transitions_path = group[\"transitions\"].values[0]\n",
    "        paths.append([chip, vv_path, vh_path, nasadem_path, change_path, extent_path, occurrence_path, recurrence_path,\n",
    "                      seasonality_path, transitions_path])\n",
    "    return pd.DataFrame(paths, columns=[\"chip_id\", \"vv_path\", \"vh_path\", \"nasadem_path\", \"change_path\", \"extent_path\", \"occurrence_path\",\n",
    "                                        \"recurrence_path\", \"seasonality_path\", \"transitions_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239ec51",
   "metadata": {
    "id": "dd7e8b49"
   },
   "outputs": [],
   "source": [
    "# Separate features from labels\n",
    "test_meta_x = get_paths_by_chip(test)\n",
    "test_meta_y = test[[\"chip_id\", \"label_path\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "train_meta_x = get_paths_by_chip(train)\n",
    "train_meta_y = train[[\"chip_id\", \"label_path\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d89e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "RvRFbu8vDH52",
    "outputId": "91697105-c64b-45cf-cf14-24e0add983e6"
   },
   "outputs": [],
   "source": [
    "train_meta_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e54e7c",
   "metadata": {
    "id": "d5d72bcf"
   },
   "source": [
    "## Get the images from the train and test metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1634b54",
   "metadata": {
    "id": "Q15ZfTHDusc5"
   },
   "outputs": [],
   "source": [
    "def progress(value, max=100):\n",
    "    return HTML(\"\"\"\n",
    "        <progress value='{value}', max='{max}', style='width: 100%'> {value} </progress>\n",
    "    \"\"\".format(value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaafb6",
   "metadata": {
    "id": "eb8480e8"
   },
   "outputs": [],
   "source": [
    "def numpy_mask(image_path):\n",
    "    with rasterio.open(image_path) as img:\n",
    "        return img.read(1, masked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c8436",
   "metadata": {
    "id": "cd038083"
   },
   "outputs": [],
   "source": [
    "def get_images(feature_path, label_path):\n",
    "    features = []\n",
    "    labels = []\n",
    "    masks = []\n",
    "\n",
    "    #progress bar\n",
    "    out1 = display(progress(0, 100), display_id=True)\n",
    "    out2 = display(progress(0, 100), display_id=True)\n",
    "\n",
    "    paths = label_path['label_path'].to_list()\n",
    "    nb_cols = len(paths)\n",
    "    #load labels\n",
    "    for i in range(nb_cols):\n",
    "        with rasterio.open(paths[i]) as lp:\n",
    "            img = lp.read(1)\n",
    "\n",
    "        #create a list of mask for missing pixels\n",
    "        mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "        mask[np.where(img == 255)] = 1\n",
    "\n",
    "        labels.append(ma.array(img.astype('float32'), mask = mask))\n",
    "        masks.append(mask)\n",
    "\n",
    "        out2.update(progress((i/nb_cols)*100, 100))\n",
    "\n",
    "    #load features\n",
    "    cols = [\"vv_path\", \"vh_path\", \"nasadem_path\", \"change_path\", \"extent_path\", \"seasonality_path\", \"occurrence_path\", \"recurrence_path\", \"transitions_path\"]\n",
    "    nb_cols = len(feature_path)\n",
    "    for row in range(nb_cols) :\n",
    "      images = []\n",
    "      for col in cols:\n",
    "        with rasterio.open(feature_path.loc[row, col]) as img:\n",
    "          #load the tif file\n",
    "          if(col in [\"vv_path\", \"vh_path\"]):\n",
    "              #apply transformation: clip values out of -30;0 range and map them to 0; 255 range then convert to uint8\n",
    "              images.append(ma.array(np.uint8(np.clip(img.read(1), -30, 0)*(-8.4)), mask = masks[row]))\n",
    "          elif col == \"nasadem_path\":\n",
    "              #clip values > 255 and converto to uint8\n",
    "              images.append(ma.array(np.uint8(np.clip(img.read(1), 0, 255)), mask = masks[row]))\n",
    "          else:\n",
    "              #no transformation, values are already between 0 and 255 and in uint8 format\n",
    "              images.append(ma.array(img.read(1), mask = masks[row]))\n",
    "          #apply the mask\n",
    "            #img = ma.array(img, mask = masks[row])\n",
    "          #stack the images in one array\n",
    "          #images.append(img)\n",
    "      features.append(np.stack(images, axis=-1))\n",
    "      out2.update(progress((row/nb_cols)*100, 100))       \n",
    "            \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbda24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "4a845e32",
    "outputId": "4e71f676-ffcb-4f07-a5ea-76cb6f4ad600"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = get_images(train_meta_x, train_meta_y)\n",
    "test_x, test_y = get_images(test_meta_x, test_meta_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1148f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3c2fba1",
    "outputId": "6263796b-a0a4-46c1-e479-0faf3cd657e9"
   },
   "outputs": [],
   "source": [
    "(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d940575",
   "metadata": {
    "id": "cku48629Blzo"
   },
   "source": [
    "## Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962ab77",
   "metadata": {
    "id": "bJ19fBiWBoHa"
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        #albumentations.RandomCrop(256, 256),\n",
    "        albumentations.RandomRotate90(),\n",
    "        albumentations.HorizontalFlip(),\n",
    "        albumentations.VerticalFlip(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c158135",
   "metadata": {
    "id": "fLcwIoAmBoKM"
   },
   "outputs": [],
   "source": [
    "train_x_aug = []\n",
    "train_y_aug = []\n",
    "for i in range(len(train_x)):\n",
    "  t = transform(image=train_x[i], mask=train_y[i])\n",
    "  train_x_aug.append(t['image'])\n",
    "  train_y_aug.append(t['mask'])\n",
    "\n",
    "train_x_aug = np.array(train_x_aug)\n",
    "train_y_aug = np.array(train_y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8cd8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XqtaAvsBoMa",
    "outputId": "8f0e2390-db7b-4719-b283-74c9960920c4"
   },
   "outputs": [],
   "source": [
    "train_x_aug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8fa64",
   "metadata": {
    "id": "bCPlgy588QgT"
   },
   "source": [
    "## Display the images and the corresponding augmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b4927",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "id": "de18b02f",
    "outputId": "320c8a83-9d69-4812-b42d-091a86d7d679"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(15, 15))\n",
    "\n",
    "id = 2\n",
    "#visualize radar image\n",
    "ax[0][0].imshow(train_x[id, :, :, 0])\n",
    "ax[0][0].set_title(\"Vertical-vertical band\")\n",
    "\n",
    "ax[0][1].imshow(train_x[id, :, :, 1])\n",
    "ax[0][1].set_title(\"Vertical-horizontal band\")\n",
    "\n",
    "ax[0][2].imshow(train_y[id])\n",
    "ax[0][2].set_title(\"label\")\n",
    "\n",
    "ax[1][0].imshow(train_x_aug[id, :, :, 0])\n",
    "ax[1][0].set_title(\"augmented Vertical-vertical band\")\n",
    "\n",
    "ax[1][1].imshow(train_x_aug[id, :, :, 1])\n",
    "ax[1][1].set_title(\"augmented Vertical-horizontal band\")\n",
    "\n",
    "ax[1][2].imshow(train_y_aug[id])\n",
    "ax[1][2].set_title(\"augmented label\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527709c0",
   "metadata": {
    "id": "8XVrj8VGHqHE"
   },
   "source": [
    "# Concatenate training data and augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a01718",
   "metadata": {
    "id": "WbYk5o8kHqX9"
   },
   "outputs": [],
   "source": [
    "train_x_final = np.concatenate((train_x, train_x_aug))\n",
    "train_y_final = np.concatenate((train_y, train_y_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79715223",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Coa2KFU6H5kI",
    "outputId": "8216a8ca-cbd5-4255-9218-4cfadc51c607"
   },
   "outputs": [],
   "source": [
    "(train_x_final.shape, train_y_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba87d6",
   "metadata": {
    "id": "qe7cAeXmOAk-"
   },
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3fe23",
   "metadata": {
    "id": "XubAGmQzOFxs"
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
    "def DiceLoss_square(y_true, y_pred, smooth=1):\n",
    "  #create the missing data mask\n",
    "  mask = tf.math.not_equal(y_true, 255)\n",
    "  #apply the mask\n",
    "  y_true = tf.boolean_mask(y_true, mask)\n",
    "  y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(K.abs(y_true_f * y_pred_f))\n",
    "  return 1-((2. * intersection + smooth) / (K.sum(K.square(y_true_f),-1) + K.sum(K.square(y_pred_f),-1) + smooth))\n",
    "\n",
    "def DiceLoss(y_true, y_pred, smooth=1):\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true * y_pred)\n",
    "  return 1-((2. * intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f2775",
   "metadata": {
    "id": "C5GQhIfyOF1E"
   },
   "outputs": [],
   "source": [
    "def IOU_coef(y_true, y_pred):\n",
    "  #create the missing data mask\n",
    "  mask = tf.math.not_equal(y_true, 255)\n",
    "  #apply the mask\n",
    "  y_true = tf.boolean_mask(y_true, mask)\n",
    "  y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "  #make all values > 0.5 a 1 and all others a 0\n",
    "  y_pred = tf.cast((y_pred > 0.5), dtype=tf.float32)\n",
    "  #y_pred = tf.math.multiply(tf.math.greater(y_pred, 0.5),1.0)\n",
    "\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_f * y_pred_f)\n",
    "  return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# https://www.youtube.com/watch?v=BNPW1mYbgS4\n",
    "def IOULoss(y_true, y_pred):\n",
    "    return -IOU_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cad54",
   "metadata": {
    "id": "e52500d7"
   },
   "source": [
    "# Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8040844",
   "metadata": {
    "id": "d6146af6"
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e908f3",
   "metadata": {
    "id": "7ee9bd67"
   },
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011745e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7681243",
    "outputId": "17600a24-1d75-480e-b0ad-9fd5fe430312"
   },
   "outputs": [],
   "source": [
    "input_img = Input((img_size, img_size, 9), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=DiceLoss_square, metrics=[IOU_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe75328",
   "metadata": {
    "id": "15e5c30b"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('../../models/temporary/' + MODEL_NAME, verbose=1, save_best_only=True, save_weights_only=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87febe1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCQ8_eltVPrv",
    "outputId": "6a1fe845-8419-4582-b6b0-5b58b32cc875"
   },
   "outputs": [],
   "source": [
    "print(type(train_x_final[0,0,0,8]), type(train_y[0,0,0]))\n",
    "print(type(test_x[0,0,0,0]), type(test_y[0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab387f77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouZu6LX_Vd1a",
    "outputId": "9bf5964d-62e0-4669-eacf-a7424e02a4f8"
   },
   "outputs": [],
   "source": [
    "print(\"max train_x:\", np.amax(train_x), \"min train_x:\", np.amin(train_x))\n",
    "print(\"max train_x_aug:\", np.amax(train_x_aug), \"min train_x_aug:\", np.amin(train_x_aug))\n",
    "print(\"max test_x:\", np.amax(test_x), \"min test_x:\", np.amin(test_x))\n",
    "print(\"max train_y:\", np.amax(train_y), \"min train_y:\", np.amin(train_y))\n",
    "print(\"max test_y:\", np.amax(test_y), \"min test_y:\", np.amin(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55aa65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d900d6be",
    "outputId": "4d904a08-a13a-4d1c-a61d-fabc4f6f8aef"
   },
   "outputs": [],
   "source": [
    "results = model.fit(train_x_final, train_y_final, batch_size=8, epochs=100, callbacks=callbacks,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c150b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "cb6548fc",
    "outputId": "1e9fc10b-ca54-4595-b533-08827a1576b3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Unet - PC - image augm - Dice loss_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
